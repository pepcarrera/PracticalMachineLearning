##Data Load, Processing, and Exploration
###Load Data 
Perform data download and initial data load of the test and training data
```{r, cache=TRUE}
trainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
trainFile <- "pml-training.csv"
testURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testFile <- "pml-testing.csv"
download.file(trainURL, trainFile, method="curl")
download.file(testURL, testFile, method="curl")
train <- read.csv(trainFile,na.strings=c("NA",""))
test <-read.csv(testFile,na.strings=c("NA",""))
```
###Initial Data Exploration
```{r}
dim(test)
dim(train)
train[1:5,1:10]
str(train)
```
###Data Preperation
```{r}
#Count the number of NAs in traiing and test set
trainCols <- colSums(is.na(train))
testCols <- colSums(is.na(test))
trainNAs <- table(trainCols)
testNAs <- table(testCols)
#Number of variables with NAs in train set
trainNAs
#Number of variables with NAs in test set
testNAs
```

The results show that there are many columns with close to or only NA data in the data set.  The next step is to remove these columns from the data, alnog with removal of the following non-numeric columns:
Initial Row Index Column, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window, & num_window

```{r}
trainNAColumns <- trainCols >= 19216
testNAColumns <- testCols >= 20
trainPro <- train[!trainNAColumns]
testPro <- test[!testNAColumns]
trainPro <- trainPro[, -(1:7)] 
testPro <- testPro[, -(1:7)]
```

##Model
Here we will select the appropriate model for predicing the classe based on the features of the training data.

###Random Forest
We will use the Random Forest technique to derive our model with a 4 k-fold Cross Validation.  Because we are doing k-fold, we do not need to split out the training data to perform an out of sample error as the 4 k-fold Cross Validation feature will do this for us.
```{r}
modFit <- train(as.factor(classe) ~ ., data=trainPro, method="rf",prox=TRUE, 
        trControl = trainControl(method = "cv", number = 4, allowParallel = TRUE))
modFit
```
Based on our cross validation result, using the mtry=2 model, with an accuracy of 99.4%, we have out of sample error rate of .6%, which is very good.  

##Results
```{r}
prediction <- predict(modFit, testPro) 
prediction

#Function to write output files for programming assignment
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(as.character(predanswers))
```
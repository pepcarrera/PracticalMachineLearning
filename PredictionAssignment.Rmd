#Prediction Assignment
##Introduction

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here 

http://groupware.les.inf.puc-rio.br/har

##Data Load, Processing, and Exploration
###Load Data 
Perform data download and initial data load of the test and training data
```{r, cache=TRUE}
trainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
trainFile <- "pml-training.csv"
testURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testFile <- "pml-testing.csv"
download.file(trainURL, trainFile, method="curl")
download.file(testURL, testFile, method="curl")
train <- read.csv(trainFile,na.strings=c("NA",""))
test <-read.csv(testFile,na.strings=c("NA",""))
```
###Initial Data Exploration
Get a sense of the number of rows, variables, and types of data
```{r}
dim(test)
dim(train)
train[1:5,1:10]
str(train)
```
###Data Preperation
```{r}
#Count the number of NAs in traiing and test set
trainCols <- colSums(is.na(train))
testCols <- colSums(is.na(test))
trainNAs <- table(trainCols)
testNAs <- table(testCols)
#Number of variables with NAs in train set
trainNAs
#Number of variables with NAs in test set
testNAs
```

The results show that there are many columns with close to or only NA data in the data set.  The next step is to remove these columns from the data, alnog with removal of the following non-numeric columns:
Initial Row Index Column, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window, & num_window

```{r}
trainNAColumns <- trainCols >= 19216
testNAColumns <- testCols >= 20
trainPro <- train[!trainNAColumns]
testPro <- test[!testNAColumns]
trainPro <- trainPro[, -(1:7)] 
testPro <- testPro[, -(1:7)]
```

##Model
Here we will select the appropriate model for predicing the classe based on the features of the training data.

###Random Forest
We will use the Random Forest technique to derive our model with a 4 k-fold Cross Validation.  Because we are doing k-fold, we do not need to split out the training data to perform an out of sample error as the 4 k-fold Cross Validation feature will do this for us.
```{r}
modFit <- train(as.factor(classe) ~ ., data=trainPro, method="rf",prox=TRUE, 
        trControl = trainControl(method = "cv", number = 4, allowParallel = TRUE))
modFit
```
Based on our cross validation result, using the mtry=2 model, with an accuracy of 99.4%, we have out of sample error rate of .6%, which is very good.  

##Results
```{r}
prediction <- predict(modFit, testPro) 
prediction

#Function to write output files for programming assignment
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(as.character(prediction))
```